{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c5fc5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693c8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "\n",
    "#Block\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
    "        super().__init__()\n",
    "\n",
    "        #Downsampling code\n",
    "\n",
    "        if down:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(0.2) if act==\"leaky\" else nn.ReLU()\n",
    "            )\n",
    "\n",
    "        #Upsampling code\n",
    "\n",
    "        else: \n",
    "            self.block = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Dropout(0.5) if use_dropout else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "#UNet Model for Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"), # 128x128\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        #Encoder\n",
    "        self.down1 = Block(features, features*2, down=True, act=\"leaky\", use_dropout=False) # 64*64\n",
    "        self.down2 = Block(features*2, features*4, down=True, act=\"leaky\", use_dropout=False) # 32*32\n",
    "        self.down3 = Block(features*4, features*8, down=True, act=\"leaky\", use_dropout=False) # 16*16\n",
    "        self.down4 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False) # 8*8\n",
    "        self.down5 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False) # 4*4\n",
    "        self.down6 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False) # 2*2\n",
    "\n",
    "        #bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"), #1x1\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.up1 = Block(features*8, features*8, down=False, act=\"relu\", use_dropout=True) #2x2\n",
    "        self.up2 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True) #4x4\n",
    "        self.up3 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True) #8x8\n",
    "        self.up4 = Block(features*8*2, features*4, down=False, act=\"relu\", use_dropout=False) #16x16\n",
    "        self.up5 = Block(features*4*2, features*2, down=False, act=\"relu\", use_dropout=False) #32x32\n",
    "        self.up6 = Block(features*2*2, features, down=False, act=\"relu\", use_dropout=False) #64x64\n",
    "        self.up7 = Block(features*2, in_channels, down=False, act=\"relu\", use_dropout=False) #128x128\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        def forward(self,x):\n",
    "            d1 = self.initial_down(x)\n",
    "            d2 = self.down1(d1)\n",
    "            d3 = self.down2(d2)\n",
    "            d4 = self.down3(d3)\n",
    "            d5 = self.down4(d4)\n",
    "            d6 = self.down5(d5)\n",
    "            d7 = self.down6(d6)\n",
    "            \n",
    "            bottleneck = self.bottleneck(d7)\n",
    "            \n",
    "            up1 = self.up1(bottleneck)\n",
    "            up2 = self.up2(torch.cat([up1, d7], 1))\n",
    "            up3 = self.up3(torch.cat([up2, d6], 1))\n",
    "            up4 = self.up4(torch.cat([up3, d5], 1))\n",
    "            up5 = self.up5(torch.cat([up4, d4], 1))\n",
    "            up6 = self.up6(torch.cat([up5, d3], 1))\n",
    "            up7 = self.up7(torch.cat([up6, d2], 1))\n",
    "            \n",
    "            return self.final_up(torch.cat([up7, d1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd8b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution block\n",
    "class CNN_Block(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode=\"reflect\"),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f087c6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2a17d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial=nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        layers=[]\n",
    "        in_channels=features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(CNN_Block(in_channels,feature,stride=1 if feature==features[-1] else 2))\n",
    "            in_channels=feature\n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels,1,kernel_size=4,stride=1,padding=1,padding_mode=\"reflect\")\n",
    "        )\n",
    "        self.model=nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self,x,y):\n",
    "            x=torch.cat([x,y],dim=1)\n",
    "            x=self.initial(x)\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40114b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
